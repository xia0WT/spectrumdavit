import torch
import numpy as np

from scipy.signal import savgol_filter
from scipy import interpolate
from pymatgen.core.structure import Structure
from pymatgen.io.ase import AseAtomsAdaptor
from pymatgen.analysis.diffraction.xrd import XRDCalculator
import matplotlib.pyplot as plt
from functools import reduce
import argparse
import yaml
import pickle
import os

from tslearn.metrics import dtw_path
from pybaselines import Baseline

from nwtk import lortzen
from .utils import read_txt_xrd
from .model.spectrumdavit_model import SpectrumDaVit
from .find_peak import FindPeaks
from .structure_generator import MaceGenerator
from nwtk.utils import create_log


class XrdPredict(object):
    def __init__(self,
                 model_config, #"../xrd_predict_unique/20250723_162449_SpectrumDaVit/args_config.yaml",  #yaml
                 model_save_dir, #"../xrd_predict_unique/20250723_162449_SpectrumDaVit/model_best.pth.tar",  #pth.tar,
                 xrd_type_file = "template/pxrd_unique_10_60_1256_remove_duplicate_label.pkl",
                 structure_frame = "template/structure_frame_unique_10_60_1256_remove_duplicate_fingerprint.pkl",
                 mace_model_paths = "../data/mace-omat-0-medium.model",
                 local_rank = 2,
                 predict_topk = 3,
                 atoms_threshold = 50,
                ):

        self.device = torch.device('cuda:%d' % local_rank) if torch.cuda.is_available() else torch.device('cpu')
        parser = argparse.ArgumentParser(description='Training Config', add_help=False)
        with open(model_config) as f:
            default_arg = yaml.safe_load(f)
        parser.set_defaults(**default_arg)
        args = parser.parse_args(args = [])

        self.model = self.model_eval(args, model_save_dir, self.device)

        self.mace_model_paths = mace_model_paths
        self.profile = lortzen.simple_profile(nmax=90, ndim=4096)

        self.atoms_threshold = atoms_threshold
        self.predict_topk = predict_topk
        self.calculator = XRDCalculator(wavelength='CuKa')
        

        with open(structure_frame, "rb") as f:
            self.frame = pickle.load(f)


        with open(xrd_type_file, "rb") as f:
            self.structure_type = pickle.load(f)

    def model_eval(self, args, model_save_dir, map_location):
        model =SpectrumDaVit(
                            in_chans=args.in_chans,
                            num_classes=args.num_classes,
                            drop_rate=args.drop,
                            drop_path_rate=args.drop_path,
                            depths=args.depths,  #(1, 1, 3, 1),
                            embed_dims=args.embed_dims,  #(96, 192, 384, 768),
                            num_heads=args.num_heads,  #(3, 6, 12, 24),
                            window_size=args.window_size,
                            ).to(self.device)

        checkpoint = torch.load(model_save_dir, map_location=map_location)
        model.load_state_dict(checkpoint['state_dict'])
        model.eval()

        return model.float()


    def find_peaks(self,
                   xrd_file,
                   work_dir = "results",
                   prominence = 8,
                   window_length=60,
                   poly_order = 3,
                   deriv = 2,
                   use_sgd=False,
                   use_dtw=True,
                   **kwargs): # make sure to match as much peaks as you can, do not match error peaks.

        if not os.path.exists(work_dir):
            os.makedirs(work_dir)
        self.work_dir = work_dir

        self._logger = create_log(os.path.join(work_dir, 'result.log'))()

        if xrd_file.endswith(".cif"):
            s = Structure.from_file(xrd_file)
            pattern = self.calculator.get_pattern(s)
            self.xrd_data = np.linspace(0,90,4096), self.profile.pseudo_voigt(pattern.x, pattern.y).squeeze()
            raw_xrd = self.xrd_data
        else:
            raw_xrd = read_txt_xrd(xrd_file)
            xrd_data = interp(*raw_xrd)
            self.xrd_data = fit_baseline(*xrd_data, poly_order=poly_order)

        self.peak = FindPeaks(*self.xrd_data).find_peak(prominence=prominence, **kwargs)
        #TODO x,y?
        self.sgdector = SGDetector(x, y, window_length=window_length, poly_order = poly_order, deriv = deriv) if use_sgd else None
        self.dtwdetector = DTWdetector(*raw_xrd, poly_order = poly_order) if use_dtw else None
        self.sgd_score = []
        self.dtw_score = []
        
    def get_structure(self, elements: list[str], **kwargs):
        mg = MaceGenerator(frame = self.frame, model_paths = self.mace_model_paths, logger = self._logger)
        crystal = []
        indices = self._predict(self.peak, self.model, self.predict_topk).tolist()
        if not isinstance(indices, list):
            indices = [indices]
        for j,i in enumerate(indices):
            self._logger.info(f"===========STARTING TOP {j} PREDICTION===========")
            s = self.structure_type[i]
            if s in self.frame:
                c, e = mg.from_elements(s, elements,atoms_threshold = self.atoms_threshold, **kwargs)
                crystal.append(c)
        crystal = reduce(lambda a, b: a + b, crystal)
        self.compare_xrd(crystal)
        sgdsc = sorted(self.sgd_score, key=lambda i:i[1],reverse = True)
        dtwsc = sorted(self.dtw_score, key=lambda i:i[1])

        self._summary(sgdsc, dtwsc)

    def _summary(self, sgdsc, dtwsc):
        self._logger.info(f"==============GROUND TRUTH SUMMARY==============")
        for i,j in zip(sgdsc[:3],("1st", "2nd", "3rd")):
            self._logger.info(f"The {j} similar structure index is {i[0]}, score is {i[1]}")

        for i,j in zip(dtwsc[:3],("1st", "2nd", "3rd")):
            self._logger.info(f"The {j} similar structure index according DTW is {i[0]},  score is {i[1]}")

    @torch.no_grad()
    def _predict(self, peaks, model, top_k):
        profiled_xrd = self.profile.pseudo_voigt(*self.peak)
        pr = torch.tensor(profiled_xrd.squeeze()[np.newaxis, np.newaxis], dtype = torch.float32).to(self.device)
        output = model(pr)
        k = torch.topk(output, top_k).indices.squeeze()
        return k.detach().to("cpu")

    def compare_xrd(self, crystals):
        for i, c in enumerate(crystals):
            strcuture = AseAtomsAdaptor.get_structure(c)
            self.plot_vs_xrd(strcuture, i, self.work_dir)

    def plot_vs_xrd(self, structure, index, pic_save_dir):
        
        pattern = self.calculator.get_pattern(structure)
        xrd_x , xrd_y = self.xrd_data
        formula = structure.formula.replace(" ","")
        fig, ax = plt.subplots()
        ax.plot(xrd_x, xrd_y*100/ max(xrd_y), color = "r", label="XRD")
        ax.vlines(pattern.x, 0, pattern.y, color = "b", label="characterise peaks")
        ax.set_ylim(0)
        ax.set_ylabel("intensity")
        ax.set_xlabel("2Î¸")
        ax.grid()
        ax.legend()
        ax.set_title(f"Exp XRD vs Theory {formula}--{index}")
        
        if self.dtwdetector:
            profiled = self.profile.pseudo_voigt(pattern.x, pattern.y)
            _dtw_score = self.dtwdetector(profiled)
            self.dtw_score.append((index, _dtw_score))
            self._logger.info(f"Structure index: {index}, formula: {formula}, DTW score: {_dtw_score}")
        if self.sgdector:
            _sgd_score = self.sgdector(pattern)
            self.sgd_score.append((index, _sgd_score))
            self._logger.info(f"Structure index: {index}, formula: {formula}, similarity score: {_sgd_score}")
        if not os.path.exists(pic_save_dir):
            os.mkdir(pic_save_dir)
        plt.close(fig)
        fig.savefig(os.path.join(pic_save_dir, f"{formula}--{index}.png"), dpi = 300)
        structure.to(os.path.join(pic_save_dir, f"{formula}--{index}.cif"), fmt = "cif")
        
        
class SGDetector(object):
    def __init__(self, x, y, window_length, poly_order, deriv):
        self.f = savgol_filter(y,
                        window_length = window_length,
                        polyorder=poly_order,
                        deriv = deriv)
        self.x = x

    def __call__(self, pattern):
        index = (pattern.x - self.x.min()) / (self.x.max() - self.x.min()) * len(self.x)
        c = np.select([index<len(self.x)],[index]).astype(int)
        c = c[c != 0]
        t = abs(self.f[c])
        k = np.sum(t)
        return k

class DTWdetector(object):
    def __init__(self, x, y, poly_order):
        interp_xrd = interp(x, y, extrapolate=True) # fit_baseline(x, y, poly_order=poly_order)
        _, self.xrd_y = fit_baseline(*interp_xrd, poly_order = poly_order)

    def __call__(self, y, sakoe_chiba_radius=50):
        _, cost = dtw_path(self.xrd_y, y, sakoe_chiba_radius=sakoe_chiba_radius)
        return cost


def interp(x, y, extrapolate=False, kind = "nearest-up"):
    y = y / y.max() *100
    fill_value = "extrapolate" if extrapolate else None
    f = interpolate.interp1d(x, y, kind = "nearest-up", fill_value=fill_value)
    if extrapolate:
        x = np.linspace(0, 90, 4096)
    else:
        x = np.linspace(x.min(), x.max(), 4096)
    y = f(x)
    return x, y

def fit_baseline(x, y, poly_order):
    baseline_fitter = Baseline(x_data=x)
    bkg_1, params_1 = baseline_fitter.modpoly(y, poly_order=poly_order)
    return x, y-bkg_1
